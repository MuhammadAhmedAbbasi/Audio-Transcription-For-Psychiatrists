{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:815: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:1398: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:815: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:1398: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:815: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:1398: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:815: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:1398: SyntaxWarning: invalid escape sequence '\\w'\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "import librosa\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import Audio as IPythonAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for recording\n",
    "duration = 5  # seconds\n",
    "sample_rate = 22050  # Hz, the default for librosa or your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = r'C:\\Users\\Administrator\\Desktop\\Backend-Algorithm-LLM\\Algorithm\\audio_text_llm\\SenseVoiceSmall\\audio_sample\\North vs. South Chinese Accent.mp3'\n",
    "speech, sample_rate = librosa.load(audio_path, sr = None)\n",
    "\n",
    "# If the sample rate is not 16,000 Hz, resample the audio\n",
    "target_sample_rate = 16000\n",
    "if sample_rate != target_sample_rate:\n",
    "    speech = librosa.resample(speech, orig_sr=sample_rate, target_sr=target_sample_rate)\n",
    "    sample_rate = target_sample_rate  # Update the sample rate\n",
    "\n",
    "speech = speech[:int(900000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a band-pass filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "# Function to apply the band-pass filter\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Set your low and high cut-off frequencies (in Hz)\n",
    "lowcut = 1000.0\n",
    "highcut = 3400.0\n",
    "\n",
    "# Apply the band-pass filter\n",
    "filtered_speech = bandpass_filter(speech, lowcut, highcut, target_sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate: 16000\n",
      "Audio Array: [ 0.          0.          0.         ... -0.01914331 -0.0403462\n",
      " -0.03032975]\n",
      "Audio Array datatype is Array:  True\n"
     ]
    }
   ],
   "source": [
    "# Print details\n",
    "print(\"Sample Rate:\", sample_rate)\n",
    "print(\"Audio Array:\", filtered_speech)\n",
    "print(\"Audio Array datatype is Array: \", isinstance(speech,np.ndarray) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New version available: 1.1.12. Your current version is 1.1.2.\n",
      "Please use the command \"pip install -U funasr\" to upgrade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 15:03:06,665 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\train_utils\\load_pretrained_model.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  src_state = torch.load(path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "chunk_size = [0, 10, 5]  # [0, 10, 5] 600ms, [0, 8, 4] 480ms\n",
    "encoder_chunk_look_back = 4  # number of chunks to lookback for encoder self-attention\n",
    "decoder_chunk_look_back = 1  # number of encoder chunks to lookback for decoder cross-attention\n",
    "\n",
    "model = AutoModel(model=\"paraformer-zh-streaming\", model_revision=\"v2.0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.144: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.49it/s]                                                                                          \n",
      "rtf_avg: 0.119: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.79it/s]                                                                                          \n",
      "rtf_avg: 0.123: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.34it/s]                                                                                          \n",
      "rtf_avg: 0.126: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.14it/s]                                                                                          \n",
      "rtf_avg: 0.165: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.98it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.90it/s]                                                                                          \n",
      "rtf_avg: 0.122: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.54it/s]                                                                                          \n",
      "rtf_avg: 0.115: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.37it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.98it/s]                                                                                          \n",
      "rtf_avg: 0.120: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.62it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.04it/s]                                                                                          \n",
      "rtf_avg: 0.117: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.02it/s]                                                                                          \n",
      "rtf_avg: 0.182: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.10it/s]                                                                                          \n",
      "rtf_avg: 0.167: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.92it/s]                                                                                          \n",
      "rtf_avg: 0.152: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.82it/s]                                                                                          \n",
      "rtf_avg: 0.165: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.02it/s]                                                                                          \n",
      "rtf_avg: 0.120: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.85it/s]                                                                                          \n",
      "rtf_avg: 0.148: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.07it/s]                                                                                          \n",
      "rtf_avg: 0.151: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.88it/s]                                                                                          \n",
      "rtf_avg: 0.187: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.80it/s]                                                                                          \n",
      "rtf_avg: 0.153: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.84it/s]                                                                                          \n",
      "rtf_avg: 0.115: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.34it/s]                                                                                          \n",
      "rtf_avg: 0.173: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.46it/s]                                                                                          \n",
      "rtf_avg: 0.169: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.72it/s]                                                                                          \n",
      "rtf_avg: 0.186: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.78it/s]                                                                                          \n",
      "rtf_avg: 0.211: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  7.83it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.37it/s]                                                                                          \n",
      "rtf_avg: 0.157: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.40it/s]                                                                                          \n",
      "rtf_avg: 0.154: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.71it/s]                                                                                          \n",
      "rtf_avg: 0.162: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.17it/s]                                                                                          \n",
      "rtf_avg: 0.153: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.84it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.39it/s]                                                                                          \n",
      "rtf_avg: 0.152: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.96it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.85it/s]                                                                                          \n",
      "rtf_avg: 0.166: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.84it/s]                                                                                          \n",
      "rtf_avg: 0.157: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.50it/s]                                                                                          \n",
      "rtf_avg: 0.165: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.02it/s]                                                                                          \n",
      "rtf_avg: 0.124: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.32it/s]                                                                                          \n",
      "rtf_avg: 0.169: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.77it/s]                                                                                          \n",
      "rtf_avg: 0.153: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.85it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.55it/s]                                                                                          \n",
      "rtf_avg: 0.147: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.21it/s]                                                                                          \n",
      "rtf_avg: 0.164: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.98it/s]                                                                                          \n",
      "rtf_avg: 0.171: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.58it/s]                                                                                          \n",
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.40it/s]                                                                                          \n",
      "rtf_avg: 0.166: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.89it/s]                                                                                          \n",
      "rtf_avg: 0.198: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.25it/s]                                                                                          \n",
      "rtf_avg: 0.137: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 12.00it/s]                                                                                          \n",
      "rtf_avg: 0.190: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.72it/s]                                                                                          \n",
      "rtf_avg: 0.149: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.03it/s]                                                                                          \n",
      "rtf_avg: 0.162: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.08it/s]                                                                                          \n",
      "rtf_avg: 0.161: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.25it/s]                                                                                          \n",
      "rtf_avg: 0.161: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.31it/s]                                                                                          \n",
      "rtf_avg: 0.160: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.32it/s]                                                                                          \n",
      "rtf_avg: 0.155: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.70it/s]                                                                                          \n",
      "rtf_avg: 0.125: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.06it/s]                                                                                          \n",
      "rtf_avg: 0.176: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.38it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.32it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.61it/s]                                                                                          \n",
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.51it/s]                                                                                          \n",
      "rtf_avg: 0.160: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.31it/s]                                                                                          \n",
      "rtf_avg: 0.155: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.67it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.36it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.63it/s]                                                                                          \n",
      "rtf_avg: 0.153: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.71it/s]                                                                                          \n",
      "rtf_avg: 0.123: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.50it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.61it/s]                                                                                          \n",
      "rtf_avg: 0.210: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  7.77it/s]                                                                                          \n",
      "rtf_avg: 0.182: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.02it/s]                                                                                          \n",
      "rtf_avg: 0.166: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.98it/s]                                                                                          \n",
      "rtf_avg: 0.151: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.87it/s]                                                                                          \n",
      "rtf_avg: 0.121: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.63it/s]                                                                                          \n",
      "rtf_avg: 0.160: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.41it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.35it/s]                                                                                          \n",
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.44it/s]                                                                                          \n",
      "rtf_avg: 0.121: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.74it/s]                                                                                          \n",
      "rtf_avg: 0.157: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.56it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.66it/s]                                                                                          \n",
      "rtf_avg: 0.126: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 12.95it/s]                                                                                          \n",
      "rtf_avg: 0.166: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.89it/s]                                                                                          \n",
      "rtf_avg: 0.194: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.43it/s]                                                                                          \n",
      "rtf_avg: 0.145: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.32it/s]                                                                                          \n",
      "rtf_avg: 0.167: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.91it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.31it/s]                                                                                          \n",
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.45it/s]                                                                                          \n",
      "rtf_avg: 0.162: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.14it/s]                                                                                          \n",
      "rtf_avg: 0.155: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.57it/s]                                                                                          \n",
      "rtf_avg: 0.124: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.24it/s]                                                                                          \n",
      "rtf_avg: 0.154: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.68it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.39it/s]                                                                                          \n",
      "rtf_avg: 0.183: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.90it/s]                                                                                          \n",
      "rtf_avg: 0.191: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.69it/s]                                                                                          \n",
      "rtf_avg: 0.170: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.58it/s]                                                                                          \n",
      "rtf_avg: 0.211: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.73it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张晓静二十九岁她来上海五年了这天早晨他向往常一样站在卫生间的洗手池前一边快速的刷着牙一边浏览着手机上客户刚刚发来的消息他的脑子里飞快地计划着今天的工作你恐怕不会相信他是那种接到工作从不抱怨而且计划和学习能力极强从不怕吃苦的人毫不夸张的说任何老板遇到他都会对他的工作能力非常满意他就职职于海的一家设计公司司\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_stride = chunk_size[1] * 960  # 600ms\n",
    "transcribed_text = []\n",
    "\n",
    "cache = {}\n",
    "total_chunk_num = int(len((filtered_speech) - 1) / chunk_stride + 1)\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = filtered_speech[i * chunk_stride:(i + 1) * chunk_stride]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size,\n",
    "                         encoder_chunk_look_back=encoder_chunk_look_back,\n",
    "                         decoder_chunk_look_back=decoder_chunk_look_back)\n",
    "    for entry in res:\n",
    "        transcribed_text.append(entry['text'])\n",
    "final_transcript = ''.join(transcribed_text)\n",
    "print(final_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Splitting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = r'C:\\Users\\Administrator\\Desktop\\Backend-LLM\\audio_text_llm\\SenseVoiceSmall\\audio_sample\\听故事学中文 Learn Chinese with 12 Stories - The Easiest Way to Improve Chinese.mp3'\n",
    "audio_array, sampling_rate = librosa.load(audio_path, sr = None)\n",
    "# List to hold transcriptions\n",
    "transcriptions = []\n",
    "model = AutoModel(\n",
    "    model='paraformer-zh',\n",
    "    # init_param = pretrained_model_path\n",
    "    )\n",
    "for start in range(0, total_samples, chunk_samples):\n",
    "    end = min(start + chunk_samples, total_samples)\n",
    "    chunk = audio_array[start:end]\n",
    "\n",
    "    # Convert chunk to 16kHz if necessary\n",
    "    # Note: Ensure your model accepts the sample rate of 16kHz or resample if needed\n",
    "    chunk_resampled = librosa.resample(chunk, orig_sr = sampling_rate, target_sr = 16000)\n",
    "\n",
    "    # Process the chunk\n",
    "    res = model.generate(\n",
    "        input=chunk_resampled,\n",
    "        cache={},\n",
    "        language=\"auto\",\n",
    "        use_itn=True,\n",
    "        batch_size_s=60,\n",
    "        merge_vad=True,\n",
    "        merge_length_s=15,\n",
    "    )\n",
    "\n",
    "    # Get the transcribed text\n",
    "    text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "    transcriptions.append(text)\n",
    "    # Combine all transcriptions into one\n",
    "full_transcription = \" \".join(transcriptions)\n",
    "# Save the transcription to a text file\n",
    "with open(\"transcription_'paraformer-zh.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(full_transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the Audio so it matches to the requirement of the model\n",
    "audio_16KHz = librosa.resample(audio_array,\n",
    "                               orig_sr=sampling_rate,\n",
    "                \n",
    "                               target_sr=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paraformer-zh model with vad_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14204\\3144003356.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  speech, sample_rate = librosa.load(audio_path, sr = None)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "audio_path = r'C:\\Users\\Administrator\\Desktop\\Backend-Algorithm-LLM\\Audio_transcription_files\\tmpw19f5zrc.wav'\n",
    "speech, sample_rate = librosa.load(audio_path, sr = None)\n",
    "\n",
    "# If the sample rate is not 16,000 Hz, resample the audio\n",
    "target_sample_rate = 16000\n",
    "if sample_rate != target_sample_rate:\n",
    "    speech = librosa.resample(speech, orig_sr=sample_rate, target_sr=target_sample_rate)\n",
    "    sample_rate = target_sample_rate  # Update the sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New version available: 1.1.12. Your current version is 1.1.2.\n",
      "Please use the command \"pip install -U funasr\" to upgrade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 17:19:51,644 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\train_utils\\load_pretrained_model.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  src_state = torch.load(path, map_location=map_location)\n",
      "2024-10-24 17:19:57,425 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2024-10-24 17:20:00,039 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2024-10-24 17:20:16,188 - modelscope - INFO - Use user-specified model revision: v2.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect model requirements, begin to install it: C:\\Users\\Administrator\\.cache\\modelscope\\hub\\iic\\speech_campplus_sv_zh-cn_16k-common\\requirements.txt\n",
      "install model requirements successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.03it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\models\\paraformer\\model.py:251: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n",
      "rtf_avg: 0.111: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.38it/s]\n",
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 5/5 [00:00<00:00, 43.05it/s]\n",
      "rtf_avg: 0.074: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.93it/s]\n",
      "rtf_avg: 0.010: 100%|\u001b[34m██████████\u001b[0m| 9/9 [00:00<00:00, 66.47it/s]\n",
      "rtf_avg: 0.054: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.48it/s]\n",
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 16/16 [00:00<00:00, 72.34it/s]\n",
      "rtf_avg: 0.043: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.02s/it]\n",
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 31/31 [00:00<00:00, 87.57it/s]\n",
      "rtf_avg: 0.041: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.24s/it]\n",
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 40/40 [00:00<00:00, 86.55it/s]\n",
      "rtf_avg: 0.042: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.25s/it]\n",
      "rtf_avg: 0.007: 100%|\u001b[34m██████████\u001b[0m| 40/40 [00:00<00:00, 90.01it/s]\n",
      "rtf_avg: -0.359: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.76it/s]\n",
      "rtf_avg: 0.065, time_speech:  112.800, time_escape: 7.325: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:07<00:00,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗯，小明，谢谢你，今天能来自上次见面，以一来你感觉怎么样？唉，我最近真的很焦虑，胸口像压着一块石头，呼吸都觉得很困难哦，我明白了，能告诉我是什么让你感到如此焦虑吗？主要就是工作上的事情，我有一个重要的项目即将到期了，我现在担心自己没办法拿到预期，听起来真的很有压力。你在想这个项目时，脑海中会出现什么样的想法呢？我总是想象自己会失败，脑海里就像循环播放着各种糟糕的结果，这听起来让人疲惫。你有没有找到一些方法来应对这些困扰你的想法？我试过深呼吸，但是有时候我觉得这只会让我更加沮丧，而不是帮助。这很正常。有些方法对每个人效果不一样，你愿意一起探讨一些其他的技巧吗？也许我们可以找到对你更有效的方法。好呀，我愿意试试。呃，那么除了工作上的压力，你在生活中还有其他让你感到困扰的事情。嗯，其实还有一些我和朋友的关系也有点紧张，感觉大家都忙着自己的生活，很很少有时间见面。嗯，那听起来有些孤独，你是否有尝试跟他们沟通，表达你的感受呢？我有试过，但是每次都不知道怎么开口，感觉他们怕他们觉得我是在抱怨哦，我理解沟通有时确实很困难，或许我们可以一起练习一下，找找合适的表达方式。好的，这样我会觉得很有信心。嗯，太好了，我们也可以探讨如何在工作和人际关系中找到平衡，帮助你减轻压力。我很期待能学到这些。谢谢您。李医生啊，不用谢小明，你的勇气值得赞上，我们会一起努力的。\n",
      "Text:  嗯，\n",
      "Speaker:  0\n",
      "Text:  小明，\n",
      "Speaker:  0\n",
      "Text:  谢谢你，\n",
      "Speaker:  0\n",
      "Text:  今天能来自上次见面，\n",
      "Speaker:  0\n",
      "Text:  以一来你感觉怎么样？\n",
      "Speaker:  0\n",
      "Text:  唉，\n",
      "Speaker:  1\n",
      "Text:  我最近真的很焦虑，\n",
      "Speaker:  1\n",
      "Text:  胸口像压着一块石头，\n",
      "Speaker:  1\n",
      "Text:  呼吸都觉得很困难哦，\n",
      "Speaker:  0\n",
      "Text:  我明白了，\n",
      "Speaker:  0\n",
      "Text:  能告诉我是什么让你感到如此焦虑吗？\n",
      "Speaker:  1\n",
      "Text:  主要就是工作上的事情，\n",
      "Speaker:  1\n",
      "Text:  我有一个重要的项目即将到期了，\n",
      "Speaker:  1\n",
      "Text:  我现在担心自己没办法拿到预期，\n",
      "Speaker:  1\n",
      "Text:  听起来真的很有压力。\n",
      "Speaker:  0\n",
      "Text:  你在想这个项目时，\n",
      "Speaker:  0\n",
      "Text:  脑海中会出现什么样的想法呢？\n",
      "Speaker:  0\n",
      "Text:  我总是想象自己会失败，\n",
      "Speaker:  1\n",
      "Text:  脑海里就像循环播放着各种糟糕的结果，\n",
      "Speaker:  1\n",
      "Text:  这听起来让人疲惫。\n",
      "Speaker:  0\n",
      "Text:  你有没有找到一些方法来应对这些困扰你的想法？\n",
      "Speaker:  0\n",
      "Text:  我试过深呼吸，\n",
      "Speaker:  1\n",
      "Text:  但是有时候我觉得这只会让我更加沮丧，\n",
      "Speaker:  1\n",
      "Text:  而不是帮助。\n",
      "Speaker:  1\n",
      "Text:  这很正常。\n",
      "Speaker:  0\n",
      "Text:  有些方法对每个人效果不一样，\n",
      "Speaker:  0\n",
      "Text:  你愿意一起探讨一些其他的技巧吗？\n",
      "Speaker:  0\n",
      "Text:  也许我们可以找到对你更有效的方法。\n",
      "Speaker:  0\n",
      "Text:  好呀，\n",
      "Speaker:  1\n",
      "Text:  我愿意试试。\n",
      "Speaker:  1\n",
      "Text:  呃，\n",
      "Speaker:  0\n",
      "Text:  那么除了工作上的压力，\n",
      "Speaker:  0\n",
      "Text:  你在生活中还有其他让你感到困扰的事情。\n",
      "Speaker:  0\n",
      "Text:  嗯，\n",
      "Speaker:  1\n",
      "Text:  其实还有一些我和朋友的关系也有点紧张，\n",
      "Speaker:  1\n",
      "Text:  感觉大家都忙着自己的生活，\n",
      "Speaker:  1\n",
      "Text:  很很少有时间见面。\n",
      "Speaker:  1\n",
      "Text:  嗯，\n",
      "Speaker:  0\n",
      "Text:  那听起来有些孤独，\n",
      "Speaker:  0\n",
      "Text:  你是否有尝试跟他们沟通，\n",
      "Speaker:  0\n",
      "Text:  表达你的感受呢？\n",
      "Speaker:  0\n",
      "Text:  我有试过，\n",
      "Speaker:  1\n",
      "Text:  但是每次都不知道怎么开口，\n",
      "Speaker:  1\n",
      "Text:  感觉他们怕他们觉得我是在抱怨哦，\n",
      "Speaker:  1\n",
      "Text:  我理解沟通有时确实很困难，\n",
      "Speaker:  0\n",
      "Text:  或许我们可以一起练习一下，\n",
      "Speaker:  0\n",
      "Text:  找找合适的表达方式。\n",
      "Speaker:  0\n",
      "Text:  好的，\n",
      "Speaker:  1\n",
      "Text:  这样我会觉得很有信心。\n",
      "Speaker:  1\n",
      "Text:  嗯，\n",
      "Speaker:  0\n",
      "Text:  太好了，\n",
      "Speaker:  0\n",
      "Text:  我们也可以探讨如何在工作和人际关系中找到平衡，\n",
      "Speaker:  0\n",
      "Text:  帮助你减轻压力。\n",
      "Speaker:  0\n",
      "Text:  我很期待能学到这些。\n",
      "Speaker:  1\n",
      "Text:  谢谢您。\n",
      "Speaker:  1\n",
      "Text:  李医生啊，\n",
      "Speaker:  0\n",
      "Text:  不用谢小明，\n",
      "Speaker:  0\n",
      "Text:  你的勇气值得赞上，\n",
      "Speaker:  0\n",
      "Text:  我们会一起努力的。\n",
      "Speaker:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel(\n",
    "    model='paraformer-zh',\n",
    "    vad_model=\"fsmn-vad\",\n",
    "    vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "    spk_model=\"cam++\", spk_model_revision=\"v2.0.2\",\n",
    "    punc_model = \"ct-punc\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)\n",
    "\n",
    "com = []\n",
    "for i in res:\n",
    "   for j in i['sentence_info']:\n",
    "      print(\"Text: \", j['text'])\n",
    "      print( \"Speaker: \", j['spk'])\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key': 'rand_key_2yW4Acq9GFz6Y',\n",
       "  'text': '嗯，小明，谢谢你，今天能来自上次见面，以一来你感觉怎么样？唉，我最近真的很焦虑，胸口像压着一块石头，呼吸都觉得很困难哦，我明白了，能告诉我是什么让你感到如此焦虑吗？主要就是工作上的事情，我有一个重要的项目即将到期了，我现在担心自己没办法拿到预期，听起来真的很有压力。你在想这个项目时，脑海中会出现什么样的想法呢？我总是想象自己会失败，脑海里就像循环播放着各种糟糕的结果，这听起来让人疲惫。你有没有找到一些方法来应对这些困扰你的想法？我试过深呼吸，但是有时候我觉得这只会让我更加沮丧，而不是帮助。这很正常。有些方法对每个人效果不一样，你愿意一起探讨一些其他的技巧吗？也许我们可以找到对你更有效的方法。好呀，我愿意试试。呃，那么除了工作上的压力，你在生活中还有其他让你感到困扰的事情。嗯，其实还有一些我和朋友的关系也有点紧张，感觉大家都忙着自己的生活，很很少有时间见面。嗯，那听起来有些孤独，你是否有尝试跟他们沟通，表达你的感受呢？我有试过，但是每次都不知道怎么开口，感觉他们怕他们觉得我是在抱怨哦，我理解沟通有时确实很困难，或许我们可以一起练习一下，找找合适的表达方式。好的，这样我会觉得很有信心。嗯，太好了，我们也可以探讨如何在工作和人际关系中找到平衡，帮助你减轻压力。我很期待能学到这些。谢谢您。李医生啊，不用谢小明，你的勇气值得赞上，我们会一起努力的。',\n",
       "  'timestamp': [[2040, 2280],\n",
       "   [2460, 2640],\n",
       "   [2640, 2880],\n",
       "   [3220, 3460],\n",
       "   [3460, 3640],\n",
       "   [3640, 3760],\n",
       "   [3760, 3880],\n",
       "   [3880, 4020],\n",
       "   [4020, 4180],\n",
       "   [4180, 4420],\n",
       "   [4720, 4960],\n",
       "   [5040, 5200],\n",
       "   [5200, 5420],\n",
       "   [5420, 5560],\n",
       "   [5560, 5800],\n",
       "   [5860, 6100],\n",
       "   [6200, 6340],\n",
       "   [6340, 6560],\n",
       "   [6560, 6700],\n",
       "   [6700, 6820],\n",
       "   [6820, 7000],\n",
       "   [7000, 7120],\n",
       "   [7120, 7200],\n",
       "   [7200, 7440],\n",
       "   [7720, 7960],\n",
       "   [8160, 8340],\n",
       "   [8340, 8500],\n",
       "   [8500, 8700],\n",
       "   [8700, 8860],\n",
       "   [8860, 8980],\n",
       "   [8980, 9200],\n",
       "   [9200, 9440],\n",
       "   [9440, 9680],\n",
       "   [9880, 10040],\n",
       "   [10040, 10280],\n",
       "   [10340, 10580],\n",
       "   [10600, 10760],\n",
       "   [10760, 10940],\n",
       "   [10940, 11060],\n",
       "   [11060, 11300],\n",
       "   [11340, 11540],\n",
       "   [11540, 11780],\n",
       "   [11920, 12080],\n",
       "   [12080, 12260],\n",
       "   [12260, 12480],\n",
       "   [12480, 12620],\n",
       "   [12620, 12740],\n",
       "   [12740, 12980],\n",
       "   [12980, 13220],\n",
       "   [13220, 13460],\n",
       "   [13660, 13900],\n",
       "   [13900, 14060],\n",
       "   [14060, 14180],\n",
       "   [14180, 14420],\n",
       "   [14420, 14660],\n",
       "   [14760, 14940],\n",
       "   [14940, 15080],\n",
       "   [15080, 15240],\n",
       "   [15240, 15360],\n",
       "   [15360, 15560],\n",
       "   [15560, 15720],\n",
       "   [15720, 15880],\n",
       "   [15880, 16020],\n",
       "   [16020, 16180],\n",
       "   [16180, 16320],\n",
       "   [16320, 16460],\n",
       "   [16460, 16620],\n",
       "   [16620, 16760],\n",
       "   [16760, 16920],\n",
       "   [16920, 17100],\n",
       "   [17100, 17340],\n",
       "   [17500, 17640],\n",
       "   [17640, 17879],\n",
       "   [17879, 18059],\n",
       "   [18059, 18200],\n",
       "   [18200, 18300],\n",
       "   [18300, 18540],\n",
       "   [18600, 18780],\n",
       "   [18780, 18920],\n",
       "   [18920, 19140],\n",
       "   [19140, 19380],\n",
       "   [19660, 19860],\n",
       "   [19860, 19960],\n",
       "   [19960, 20060],\n",
       "   [20060, 20160],\n",
       "   [20160, 20320],\n",
       "   [20320, 20500],\n",
       "   [20500, 20640],\n",
       "   [20640, 20800],\n",
       "   [20800, 21040],\n",
       "   [21080, 21220],\n",
       "   [21220, 21420],\n",
       "   [21420, 21640],\n",
       "   [21640, 21880],\n",
       "   [21940, 22140],\n",
       "   [22140, 22320],\n",
       "   [22320, 22420],\n",
       "   [22420, 22560],\n",
       "   [22560, 22720],\n",
       "   [22720, 22920],\n",
       "   [22920, 23080],\n",
       "   [23080, 23320],\n",
       "   [23320, 23460],\n",
       "   [23460, 23620],\n",
       "   [23620, 23820],\n",
       "   [23820, 23980],\n",
       "   [23980, 24160],\n",
       "   [24160, 24260],\n",
       "   [24260, 24845],\n",
       "   [26010, 26210],\n",
       "   [26210, 26310],\n",
       "   [26310, 26510],\n",
       "   [26510, 26670],\n",
       "   [26670, 26910],\n",
       "   [27010, 27150],\n",
       "   [27150, 27350],\n",
       "   [27350, 27510],\n",
       "   [27510, 27750],\n",
       "   [28050, 28170],\n",
       "   [28170, 28350],\n",
       "   [28350, 28590],\n",
       "   [28770, 28950],\n",
       "   [28950, 29090],\n",
       "   [29090, 29250],\n",
       "   [29250, 29410],\n",
       "   [29410, 29650],\n",
       "   [29850, 30010],\n",
       "   [30010, 30130],\n",
       "   [30130, 30370],\n",
       "   [30530, 30750],\n",
       "   [30750, 30910],\n",
       "   [30910, 31030],\n",
       "   [31030, 31150],\n",
       "   [31150, 31270],\n",
       "   [31270, 31350],\n",
       "   [31350, 31470],\n",
       "   [31470, 31630],\n",
       "   [31630, 31790],\n",
       "   [31790, 32030],\n",
       "   [32110, 32250],\n",
       "   [32250, 32390],\n",
       "   [32390, 32590],\n",
       "   [32590, 32750],\n",
       "   [32750, 32950],\n",
       "   [32950, 33050],\n",
       "   [33050, 33230],\n",
       "   [33230, 33450],\n",
       "   [33450, 33649],\n",
       "   [33649, 33890],\n",
       "   [34270, 34490],\n",
       "   [34490, 34670],\n",
       "   [34670, 34810],\n",
       "   [34810, 34950],\n",
       "   [34950, 35170],\n",
       "   [35170, 35370],\n",
       "   [35370, 35610],\n",
       "   [35630, 35790],\n",
       "   [35790, 35970],\n",
       "   [35970, 36110],\n",
       "   [36110, 36270],\n",
       "   [36270, 36510],\n",
       "   [36830, 37050],\n",
       "   [37050, 37230],\n",
       "   [37230, 37370],\n",
       "   [37370, 37530],\n",
       "   [37530, 37855],\n",
       "   [39340, 39540],\n",
       "   [39540, 39720],\n",
       "   [39720, 39840],\n",
       "   [39840, 40040],\n",
       "   [40040, 40140],\n",
       "   [40140, 40380],\n",
       "   [40520, 40720],\n",
       "   [40720, 40960],\n",
       "   [41100, 41200],\n",
       "   [41200, 41340],\n",
       "   [41340, 41440],\n",
       "   [41440, 41580],\n",
       "   [41580, 41680],\n",
       "   [41680, 41880],\n",
       "   [41880, 41980],\n",
       "   [41980, 42140],\n",
       "   [42140, 42280],\n",
       "   [42280, 42460],\n",
       "   [42460, 42660],\n",
       "   [42660, 42820],\n",
       "   [42820, 43000],\n",
       "   [43000, 43080],\n",
       "   [43080, 43320],\n",
       "   [43440, 43600],\n",
       "   [43600, 43720],\n",
       "   [43720, 43900],\n",
       "   [43900, 44140],\n",
       "   [44240, 44480],\n",
       "   [44500, 44740],\n",
       "   [45400, 45560],\n",
       "   [45560, 45760],\n",
       "   [45760, 45960],\n",
       "   [45960, 46120],\n",
       "   [46120, 46360],\n",
       "   [46360, 46600],\n",
       "   [46680, 46840],\n",
       "   [46840, 46960],\n",
       "   [46960, 47080],\n",
       "   [47080, 47200],\n",
       "   [47200, 47280],\n",
       "   [47280, 47380],\n",
       "   [47380, 47540],\n",
       "   [47540, 47660],\n",
       "   [47660, 47860],\n",
       "   [47860, 48020],\n",
       "   [48020, 48180],\n",
       "   [48180, 48320],\n",
       "   [48320, 48460],\n",
       "   [48460, 48620],\n",
       "   [48620, 48860],\n",
       "   [48880, 49040],\n",
       "   [49040, 49280],\n",
       "   [49520, 49720],\n",
       "   [49720, 49880],\n",
       "   [49880, 50020],\n",
       "   [50020, 50240],\n",
       "   [50240, 50480],\n",
       "   [50860, 51080],\n",
       "   [51080, 51200],\n",
       "   [51200, 51320],\n",
       "   [51320, 51560],\n",
       "   [51640, 51800],\n",
       "   [51800, 52040],\n",
       "   [52080, 52220],\n",
       "   [52220, 52460],\n",
       "   [52460, 52580],\n",
       "   [52580, 52700],\n",
       "   [52700, 52820],\n",
       "   [52820, 53060],\n",
       "   [53100, 53240],\n",
       "   [53240, 53360],\n",
       "   [53360, 53480],\n",
       "   [53480, 53660],\n",
       "   [53660, 53900],\n",
       "   [54200, 54380],\n",
       "   [54380, 54560],\n",
       "   [54560, 54640],\n",
       "   [54640, 54740],\n",
       "   [54740, 54900],\n",
       "   [54900, 55020],\n",
       "   [55020, 55219],\n",
       "   [55219, 55320],\n",
       "   [55320, 55560],\n",
       "   [55840, 55980],\n",
       "   [55980, 56160],\n",
       "   [56160, 56300],\n",
       "   [56300, 56400],\n",
       "   [56400, 56580],\n",
       "   [56580, 56820],\n",
       "   [56960, 57120],\n",
       "   [57120, 57360],\n",
       "   [57360, 57480],\n",
       "   [57480, 57720],\n",
       "   [57760, 57900],\n",
       "   [57900, 58020],\n",
       "   [58020, 58140],\n",
       "   [58140, 58260],\n",
       "   [58260, 58380],\n",
       "   [58380, 58560],\n",
       "   [58560, 58700],\n",
       "   [58700, 58860],\n",
       "   [58860, 58980],\n",
       "   [58980, 59120],\n",
       "   [59120, 59280],\n",
       "   [59280, 59520],\n",
       "   [60040, 60240],\n",
       "   [60240, 60480],\n",
       "   [60500, 60680],\n",
       "   [60680, 60840],\n",
       "   [60840, 61040],\n",
       "   [61040, 61260],\n",
       "   [61260, 61500],\n",
       "   [62200, 62440],\n",
       "   [62460, 62580],\n",
       "   [62580, 62720],\n",
       "   [62720, 62820],\n",
       "   [62820, 62940],\n",
       "   [62940, 63040],\n",
       "   [63040, 63220],\n",
       "   [63220, 63340],\n",
       "   [63340, 63540],\n",
       "   [63540, 63700],\n",
       "   [63700, 63900],\n",
       "   [63900, 64060],\n",
       "   [64060, 64200],\n",
       "   [64200, 64300],\n",
       "   [64300, 64420],\n",
       "   [64420, 64540],\n",
       "   [64540, 64660],\n",
       "   [64660, 64900],\n",
       "   [65300, 65500],\n",
       "   [65500, 65720],\n",
       "   [65720, 65860],\n",
       "   [65860, 66000],\n",
       "   [66000, 66100],\n",
       "   [66100, 66240],\n",
       "   [66240, 66340],\n",
       "   [66340, 66520],\n",
       "   [66520, 66640],\n",
       "   [66640, 66760],\n",
       "   [66760, 67000],\n",
       "   [67280, 67520],\n",
       "   [67760, 67900],\n",
       "   [67900, 68100],\n",
       "   [68100, 68260],\n",
       "   [68260, 68340],\n",
       "   [68340, 68540],\n",
       "   [68540, 68885],\n",
       "   [69170, 69290],\n",
       "   [69290, 69430],\n",
       "   [69430, 69590],\n",
       "   [69590, 69770],\n",
       "   [69770, 69910],\n",
       "   [69910, 70070],\n",
       "   [70070, 70270],\n",
       "   [70270, 70390],\n",
       "   [70390, 70490],\n",
       "   [70490, 70730],\n",
       "   [70750, 70890],\n",
       "   [70890, 71130],\n",
       "   [71570, 71730],\n",
       "   [71730, 71930],\n",
       "   [71930, 72090],\n",
       "   [72090, 72270],\n",
       "   [72270, 72450],\n",
       "   [72450, 72610],\n",
       "   [72610, 72810],\n",
       "   [72810, 72970],\n",
       "   [72970, 73090],\n",
       "   [73090, 73230],\n",
       "   [73230, 73450],\n",
       "   [73450, 73690],\n",
       "   [73850, 74090],\n",
       "   [74270, 74450],\n",
       "   [74450, 74690],\n",
       "   [74690, 74890],\n",
       "   [74890, 74990],\n",
       "   [74990, 75210],\n",
       "   [75210, 75410],\n",
       "   [75410, 75765],\n",
       "   [76500, 76740],\n",
       "   [76780, 76860],\n",
       "   [76860, 76980],\n",
       "   [76980, 77100],\n",
       "   [77100, 77280],\n",
       "   [77280, 77360],\n",
       "   [77360, 77560],\n",
       "   [77560, 77680],\n",
       "   [77680, 77920],\n",
       "   [78160, 78300],\n",
       "   [78300, 78400],\n",
       "   [78400, 78640],\n",
       "   [78720, 78920],\n",
       "   [78920, 79120],\n",
       "   [79120, 79260],\n",
       "   [79260, 79360],\n",
       "   [79360, 79480],\n",
       "   [79480, 79580],\n",
       "   [79580, 79720],\n",
       "   [79720, 79960],\n",
       "   [80080, 80200],\n",
       "   [80200, 80380],\n",
       "   [80380, 80500],\n",
       "   [80500, 80640],\n",
       "   [80640, 80800],\n",
       "   [80800, 80980],\n",
       "   [80980, 81220],\n",
       "   [81540, 81700],\n",
       "   [81700, 81900],\n",
       "   [81900, 82120],\n",
       "   [82120, 82360],\n",
       "   [82440, 82540],\n",
       "   [82540, 82740],\n",
       "   [82740, 82900],\n",
       "   [82900, 83080],\n",
       "   [83080, 83200],\n",
       "   [83200, 83360],\n",
       "   [83360, 83500],\n",
       "   [83500, 83700],\n",
       "   [83700, 83800],\n",
       "   [83800, 83940],\n",
       "   [83940, 84180],\n",
       "   [84220, 84460],\n",
       "   [85140, 85300],\n",
       "   [85300, 85540],\n",
       "   [85560, 85760],\n",
       "   [85760, 86000],\n",
       "   [86600, 86840],\n",
       "   [86860, 86960],\n",
       "   [86960, 87120],\n",
       "   [87120, 87260],\n",
       "   [87260, 87380],\n",
       "   [87380, 87580],\n",
       "   [87580, 87740],\n",
       "   [87740, 87940],\n",
       "   [87940, 88160],\n",
       "   [88160, 88400],\n",
       "   [88580, 88780],\n",
       "   [88780, 88960],\n",
       "   [88960, 89120],\n",
       "   [89120, 89360],\n",
       "   [89520, 89660],\n",
       "   [89660, 89840],\n",
       "   [89840, 89960],\n",
       "   [89960, 90160],\n",
       "   [90160, 90320],\n",
       "   [90320, 90400],\n",
       "   [90400, 90520],\n",
       "   [90520, 90680],\n",
       "   [90680, 90920],\n",
       "   [91320, 91520],\n",
       "   [91520, 91640],\n",
       "   [91640, 91720],\n",
       "   [91720, 91820],\n",
       "   [91820, 91900],\n",
       "   [91900, 92000],\n",
       "   [92000, 92080],\n",
       "   [92080, 92200],\n",
       "   [92200, 92360],\n",
       "   [92360, 92540],\n",
       "   [92540, 92620],\n",
       "   [92620, 92860],\n",
       "   [92860, 93000],\n",
       "   [93000, 93200],\n",
       "   [93200, 93360],\n",
       "   [93360, 93480],\n",
       "   [93480, 93720],\n",
       "   [93800, 93960],\n",
       "   [93960, 94100],\n",
       "   [94100, 94200],\n",
       "   [94200, 94440],\n",
       "   [94840, 95040],\n",
       "   [95040, 95280],\n",
       "   [95480, 95580],\n",
       "   [95580, 95780],\n",
       "   [95780, 95880],\n",
       "   [95880, 96060],\n",
       "   [96060, 96180],\n",
       "   [96180, 96320],\n",
       "   [96320, 96420],\n",
       "   [96420, 96620],\n",
       "   [96620, 96780],\n",
       "   [96780, 97020],\n",
       "   [97380, 97620],\n",
       "   [97680, 97800],\n",
       "   [97800, 97980],\n",
       "   [97980, 98220],\n",
       "   [98240, 98340],\n",
       "   [98340, 98460],\n",
       "   [98460, 98600],\n",
       "   [98600, 98700],\n",
       "   [98700, 98900],\n",
       "   [98900, 99000],\n",
       "   [99000, 99140],\n",
       "   [99140, 99280],\n",
       "   [99280, 99400],\n",
       "   [99400, 99540],\n",
       "   [99540, 99700],\n",
       "   [99700, 99820],\n",
       "   [99820, 100020],\n",
       "   [100020, 100120],\n",
       "   [100120, 100320],\n",
       "   [100320, 100480],\n",
       "   [100480, 100660],\n",
       "   [100660, 100800],\n",
       "   [100800, 100960],\n",
       "   [100960, 101060],\n",
       "   [101060, 101200],\n",
       "   [101200, 101440],\n",
       "   [101640, 101800],\n",
       "   [101800, 101980],\n",
       "   [101980, 102180],\n",
       "   [102180, 102340],\n",
       "   [102340, 102580],\n",
       "   [102600, 102760],\n",
       "   [102760, 103000],\n",
       "   [103180, 103300],\n",
       "   [103300, 103540],\n",
       "   [103560, 103720],\n",
       "   [103720, 103900],\n",
       "   [103900, 104040],\n",
       "   [104040, 104200],\n",
       "   [104200, 104400],\n",
       "   [104400, 104620],\n",
       "   [104620, 104860],\n",
       "   [105180, 105340],\n",
       "   [105340, 105520],\n",
       "   [105520, 105700],\n",
       "   [105700, 105780],\n",
       "   [105780, 105960],\n",
       "   [105960, 106205],\n",
       "   [106390, 106510],\n",
       "   [106510, 106610],\n",
       "   [106610, 106790],\n",
       "   [106790, 107030],\n",
       "   [107030, 107150],\n",
       "   [107150, 107390],\n",
       "   [107410, 107550],\n",
       "   [107550, 107650],\n",
       "   [107650, 107790],\n",
       "   [107790, 108010],\n",
       "   [108010, 108150],\n",
       "   [108150, 108270],\n",
       "   [108270, 108430],\n",
       "   [108430, 108670],\n",
       "   [108750, 108850],\n",
       "   [108850, 108970],\n",
       "   [108970, 109150],\n",
       "   [109150, 109250],\n",
       "   [109250, 109390],\n",
       "   [109390, 109550],\n",
       "   [109550, 109670],\n",
       "   [109670, 109935]],\n",
       "  'sentence_info': [{'text': '嗯，',\n",
       "    'start': 2040,\n",
       "    'end': 2280,\n",
       "    'timestamp': [[2040, 2280]],\n",
       "    'spk': 0},\n",
       "   {'text': '小明，',\n",
       "    'start': 2640,\n",
       "    'end': 2880,\n",
       "    'timestamp': [[2460, 2640], [2640, 2880]],\n",
       "    'spk': 0},\n",
       "   {'text': '谢谢你，',\n",
       "    'start': 3640,\n",
       "    'end': 3760,\n",
       "    'timestamp': [[3220, 3460], [3460, 3640], [3640, 3760]],\n",
       "    'spk': 0},\n",
       "   {'text': '今天能来自上次见面，',\n",
       "    'start': 5560,\n",
       "    'end': 5800,\n",
       "    'timestamp': [[3760, 3880],\n",
       "     [3880, 4020],\n",
       "     [4020, 4180],\n",
       "     [4180, 4420],\n",
       "     [4720, 4960],\n",
       "     [5040, 5200],\n",
       "     [5200, 5420],\n",
       "     [5420, 5560],\n",
       "     [5560, 5800]],\n",
       "    'spk': 0},\n",
       "   {'text': '以一来你感觉怎么样？',\n",
       "    'start': 7200,\n",
       "    'end': 7440,\n",
       "    'timestamp': [[5860, 6100],\n",
       "     [6200, 6340],\n",
       "     [6340, 6560],\n",
       "     [6560, 6700],\n",
       "     [6700, 6820],\n",
       "     [6820, 7000],\n",
       "     [7000, 7120],\n",
       "     [7120, 7200],\n",
       "     [7200, 7440]],\n",
       "    'spk': 0},\n",
       "   {'text': '唉，',\n",
       "    'start': 7720,\n",
       "    'end': 7960,\n",
       "    'timestamp': [[7720, 7960]],\n",
       "    'spk': 1},\n",
       "   {'text': '我最近真的很焦虑，',\n",
       "    'start': 9440,\n",
       "    'end': 9680,\n",
       "    'timestamp': [[8160, 8340],\n",
       "     [8340, 8500],\n",
       "     [8500, 8700],\n",
       "     [8700, 8860],\n",
       "     [8860, 8980],\n",
       "     [8980, 9200],\n",
       "     [9200, 9440],\n",
       "     [9440, 9680]],\n",
       "    'spk': 1},\n",
       "   {'text': '胸口像压着一块石头，',\n",
       "    'start': 11540,\n",
       "    'end': 11780,\n",
       "    'timestamp': [[9880, 10040],\n",
       "     [10040, 10280],\n",
       "     [10340, 10580],\n",
       "     [10600, 10760],\n",
       "     [10760, 10940],\n",
       "     [10940, 11060],\n",
       "     [11060, 11300],\n",
       "     [11340, 11540],\n",
       "     [11540, 11780]],\n",
       "    'spk': 1},\n",
       "   {'text': '呼吸都觉得很困难哦，',\n",
       "    'start': 13660,\n",
       "    'end': 13900,\n",
       "    'timestamp': [[11920, 12080],\n",
       "     [12080, 12260],\n",
       "     [12260, 12480],\n",
       "     [12480, 12620],\n",
       "     [12620, 12740],\n",
       "     [12740, 12980],\n",
       "     [12980, 13220],\n",
       "     [13220, 13460],\n",
       "     [13660, 13900]],\n",
       "    'spk': 0},\n",
       "   {'text': '我明白了，',\n",
       "    'start': 14420,\n",
       "    'end': 14660,\n",
       "    'timestamp': [[13900, 14060],\n",
       "     [14060, 14180],\n",
       "     [14180, 14420],\n",
       "     [14420, 14660]],\n",
       "    'spk': 0},\n",
       "   {'text': '能告诉我是什么让你感到如此焦虑吗？',\n",
       "    'start': 17100,\n",
       "    'end': 17340,\n",
       "    'timestamp': [[14760, 14940],\n",
       "     [14940, 15080],\n",
       "     [15080, 15240],\n",
       "     [15240, 15360],\n",
       "     [15360, 15560],\n",
       "     [15560, 15720],\n",
       "     [15720, 15880],\n",
       "     [15880, 16020],\n",
       "     [16020, 16180],\n",
       "     [16180, 16320],\n",
       "     [16320, 16460],\n",
       "     [16460, 16620],\n",
       "     [16620, 16760],\n",
       "     [16760, 16920],\n",
       "     [16920, 17100],\n",
       "     [17100, 17340]],\n",
       "    'spk': 1},\n",
       "   {'text': '主要就是工作上的事情，',\n",
       "    'start': 19140,\n",
       "    'end': 19380,\n",
       "    'timestamp': [[17500, 17640],\n",
       "     [17640, 17879],\n",
       "     [17879, 18059],\n",
       "     [18059, 18200],\n",
       "     [18200, 18300],\n",
       "     [18300, 18540],\n",
       "     [18600, 18780],\n",
       "     [18780, 18920],\n",
       "     [18920, 19140],\n",
       "     [19140, 19380]],\n",
       "    'spk': 1},\n",
       "   {'text': '我有一个重要的项目即将到期了，',\n",
       "    'start': 21940,\n",
       "    'end': 22140,\n",
       "    'timestamp': [[19660, 19860],\n",
       "     [19860, 19960],\n",
       "     [19960, 20060],\n",
       "     [20060, 20160],\n",
       "     [20160, 20320],\n",
       "     [20320, 20500],\n",
       "     [20500, 20640],\n",
       "     [20640, 20800],\n",
       "     [20800, 21040],\n",
       "     [21080, 21220],\n",
       "     [21220, 21420],\n",
       "     [21420, 21640],\n",
       "     [21640, 21880],\n",
       "     [21940, 22140]],\n",
       "    'spk': 1},\n",
       "   {'text': '我现在担心自己没办法拿到预期，',\n",
       "    'start': 24260,\n",
       "    'end': 24845,\n",
       "    'timestamp': [[22140, 22320],\n",
       "     [22320, 22420],\n",
       "     [22420, 22560],\n",
       "     [22560, 22720],\n",
       "     [22720, 22920],\n",
       "     [22920, 23080],\n",
       "     [23080, 23320],\n",
       "     [23320, 23460],\n",
       "     [23460, 23620],\n",
       "     [23620, 23820],\n",
       "     [23820, 23980],\n",
       "     [23980, 24160],\n",
       "     [24160, 24260],\n",
       "     [24260, 24845]],\n",
       "    'spk': 1},\n",
       "   {'text': '听起来真的很有压力。',\n",
       "    'start': 27510,\n",
       "    'end': 27750,\n",
       "    'timestamp': [[26010, 26210],\n",
       "     [26210, 26310],\n",
       "     [26310, 26510],\n",
       "     [26510, 26670],\n",
       "     [26670, 26910],\n",
       "     [27010, 27150],\n",
       "     [27150, 27350],\n",
       "     [27350, 27510],\n",
       "     [27510, 27750]],\n",
       "    'spk': 0},\n",
       "   {'text': '你在想这个项目时，',\n",
       "    'start': 29410,\n",
       "    'end': 29650,\n",
       "    'timestamp': [[28050, 28170],\n",
       "     [28170, 28350],\n",
       "     [28350, 28590],\n",
       "     [28770, 28950],\n",
       "     [28950, 29090],\n",
       "     [29090, 29250],\n",
       "     [29250, 29410],\n",
       "     [29410, 29650]],\n",
       "    'spk': 0},\n",
       "   {'text': '脑海中会出现什么样的想法呢？',\n",
       "    'start': 31790,\n",
       "    'end': 32030,\n",
       "    'timestamp': [[29850, 30010],\n",
       "     [30010, 30130],\n",
       "     [30130, 30370],\n",
       "     [30530, 30750],\n",
       "     [30750, 30910],\n",
       "     [30910, 31030],\n",
       "     [31030, 31150],\n",
       "     [31150, 31270],\n",
       "     [31270, 31350],\n",
       "     [31350, 31470],\n",
       "     [31470, 31630],\n",
       "     [31630, 31790],\n",
       "     [31790, 32030]],\n",
       "    'spk': 0},\n",
       "   {'text': '我总是想象自己会失败，',\n",
       "    'start': 33649,\n",
       "    'end': 33890,\n",
       "    'timestamp': [[32110, 32250],\n",
       "     [32250, 32390],\n",
       "     [32390, 32590],\n",
       "     [32590, 32750],\n",
       "     [32750, 32950],\n",
       "     [32950, 33050],\n",
       "     [33050, 33230],\n",
       "     [33230, 33450],\n",
       "     [33450, 33649],\n",
       "     [33649, 33890]],\n",
       "    'spk': 1},\n",
       "   {'text': '脑海里就像循环播放着各种糟糕的结果，',\n",
       "    'start': 37530,\n",
       "    'end': 37855,\n",
       "    'timestamp': [[34270, 34490],\n",
       "     [34490, 34670],\n",
       "     [34670, 34810],\n",
       "     [34810, 34950],\n",
       "     [34950, 35170],\n",
       "     [35170, 35370],\n",
       "     [35370, 35610],\n",
       "     [35630, 35790],\n",
       "     [35790, 35970],\n",
       "     [35970, 36110],\n",
       "     [36110, 36270],\n",
       "     [36270, 36510],\n",
       "     [36830, 37050],\n",
       "     [37050, 37230],\n",
       "     [37230, 37370],\n",
       "     [37370, 37530],\n",
       "     [37530, 37855]],\n",
       "    'spk': 1},\n",
       "   {'text': '这听起来让人疲惫。',\n",
       "    'start': 40720,\n",
       "    'end': 40960,\n",
       "    'timestamp': [[39340, 39540],\n",
       "     [39540, 39720],\n",
       "     [39720, 39840],\n",
       "     [39840, 40040],\n",
       "     [40040, 40140],\n",
       "     [40140, 40380],\n",
       "     [40520, 40720],\n",
       "     [40720, 40960]],\n",
       "    'spk': 0},\n",
       "   {'text': '你有没有找到一些方法来应对这些困扰你的想法？',\n",
       "    'start': 44500,\n",
       "    'end': 44740,\n",
       "    'timestamp': [[41100, 41200],\n",
       "     [41200, 41340],\n",
       "     [41340, 41440],\n",
       "     [41440, 41580],\n",
       "     [41580, 41680],\n",
       "     [41680, 41880],\n",
       "     [41880, 41980],\n",
       "     [41980, 42140],\n",
       "     [42140, 42280],\n",
       "     [42280, 42460],\n",
       "     [42460, 42660],\n",
       "     [42660, 42820],\n",
       "     [42820, 43000],\n",
       "     [43000, 43080],\n",
       "     [43080, 43320],\n",
       "     [43440, 43600],\n",
       "     [43600, 43720],\n",
       "     [43720, 43900],\n",
       "     [43900, 44140],\n",
       "     [44240, 44480],\n",
       "     [44500, 44740]],\n",
       "    'spk': 0},\n",
       "   {'text': '我试过深呼吸，',\n",
       "    'start': 46360,\n",
       "    'end': 46600,\n",
       "    'timestamp': [[45400, 45560],\n",
       "     [45560, 45760],\n",
       "     [45760, 45960],\n",
       "     [45960, 46120],\n",
       "     [46120, 46360],\n",
       "     [46360, 46600]],\n",
       "    'spk': 1},\n",
       "   {'text': '但是有时候我觉得这只会让我更加沮丧，',\n",
       "    'start': 49040,\n",
       "    'end': 49280,\n",
       "    'timestamp': [[46680, 46840],\n",
       "     [46840, 46960],\n",
       "     [46960, 47080],\n",
       "     [47080, 47200],\n",
       "     [47200, 47280],\n",
       "     [47280, 47380],\n",
       "     [47380, 47540],\n",
       "     [47540, 47660],\n",
       "     [47660, 47860],\n",
       "     [47860, 48020],\n",
       "     [48020, 48180],\n",
       "     [48180, 48320],\n",
       "     [48320, 48460],\n",
       "     [48460, 48620],\n",
       "     [48620, 48860],\n",
       "     [48880, 49040],\n",
       "     [49040, 49280]],\n",
       "    'spk': 1},\n",
       "   {'text': '而不是帮助。',\n",
       "    'start': 50240,\n",
       "    'end': 50480,\n",
       "    'timestamp': [[49520, 49720],\n",
       "     [49720, 49880],\n",
       "     [49880, 50020],\n",
       "     [50020, 50240],\n",
       "     [50240, 50480]],\n",
       "    'spk': 1},\n",
       "   {'text': '这很正常。',\n",
       "    'start': 51320,\n",
       "    'end': 51560,\n",
       "    'timestamp': [[50860, 51080],\n",
       "     [51080, 51200],\n",
       "     [51200, 51320],\n",
       "     [51320, 51560]],\n",
       "    'spk': 0},\n",
       "   {'text': '有些方法对每个人效果不一样，',\n",
       "    'start': 53660,\n",
       "    'end': 53900,\n",
       "    'timestamp': [[51640, 51800],\n",
       "     [51800, 52040],\n",
       "     [52080, 52220],\n",
       "     [52220, 52460],\n",
       "     [52460, 52580],\n",
       "     [52580, 52700],\n",
       "     [52700, 52820],\n",
       "     [52820, 53060],\n",
       "     [53100, 53240],\n",
       "     [53240, 53360],\n",
       "     [53360, 53480],\n",
       "     [53480, 53660],\n",
       "     [53660, 53900]],\n",
       "    'spk': 0},\n",
       "   {'text': '你愿意一起探讨一些其他的技巧吗？',\n",
       "    'start': 56580,\n",
       "    'end': 56820,\n",
       "    'timestamp': [[54200, 54380],\n",
       "     [54380, 54560],\n",
       "     [54560, 54640],\n",
       "     [54640, 54740],\n",
       "     [54740, 54900],\n",
       "     [54900, 55020],\n",
       "     [55020, 55219],\n",
       "     [55219, 55320],\n",
       "     [55320, 55560],\n",
       "     [55840, 55980],\n",
       "     [55980, 56160],\n",
       "     [56160, 56300],\n",
       "     [56300, 56400],\n",
       "     [56400, 56580],\n",
       "     [56580, 56820]],\n",
       "    'spk': 0},\n",
       "   {'text': '也许我们可以找到对你更有效的方法。',\n",
       "    'start': 59280,\n",
       "    'end': 59520,\n",
       "    'timestamp': [[56960, 57120],\n",
       "     [57120, 57360],\n",
       "     [57360, 57480],\n",
       "     [57480, 57720],\n",
       "     [57760, 57900],\n",
       "     [57900, 58020],\n",
       "     [58020, 58140],\n",
       "     [58140, 58260],\n",
       "     [58260, 58380],\n",
       "     [58380, 58560],\n",
       "     [58560, 58700],\n",
       "     [58700, 58860],\n",
       "     [58860, 58980],\n",
       "     [58980, 59120],\n",
       "     [59120, 59280],\n",
       "     [59280, 59520]],\n",
       "    'spk': 0},\n",
       "   {'text': '好呀，',\n",
       "    'start': 60240,\n",
       "    'end': 60480,\n",
       "    'timestamp': [[60040, 60240], [60240, 60480]],\n",
       "    'spk': 1},\n",
       "   {'text': '我愿意试试。',\n",
       "    'start': 61260,\n",
       "    'end': 61500,\n",
       "    'timestamp': [[60500, 60680],\n",
       "     [60680, 60840],\n",
       "     [60840, 61040],\n",
       "     [61040, 61260],\n",
       "     [61260, 61500]],\n",
       "    'spk': 1},\n",
       "   {'text': '呃，',\n",
       "    'start': 62200,\n",
       "    'end': 62440,\n",
       "    'timestamp': [[62200, 62440]],\n",
       "    'spk': 0},\n",
       "   {'text': '那么除了工作上的压力，',\n",
       "    'start': 63700,\n",
       "    'end': 63900,\n",
       "    'timestamp': [[62460, 62580],\n",
       "     [62580, 62720],\n",
       "     [62720, 62820],\n",
       "     [62820, 62940],\n",
       "     [62940, 63040],\n",
       "     [63040, 63220],\n",
       "     [63220, 63340],\n",
       "     [63340, 63540],\n",
       "     [63540, 63700],\n",
       "     [63700, 63900]],\n",
       "    'spk': 0},\n",
       "   {'text': '你在生活中还有其他让你感到困扰的事情。',\n",
       "    'start': 66760,\n",
       "    'end': 67000,\n",
       "    'timestamp': [[63900, 64060],\n",
       "     [64060, 64200],\n",
       "     [64200, 64300],\n",
       "     [64300, 64420],\n",
       "     [64420, 64540],\n",
       "     [64540, 64660],\n",
       "     [64660, 64900],\n",
       "     [65300, 65500],\n",
       "     [65500, 65720],\n",
       "     [65720, 65860],\n",
       "     [65860, 66000],\n",
       "     [66000, 66100],\n",
       "     [66100, 66240],\n",
       "     [66240, 66340],\n",
       "     [66340, 66520],\n",
       "     [66520, 66640],\n",
       "     [66640, 66760],\n",
       "     [66760, 67000]],\n",
       "    'spk': 0},\n",
       "   {'text': '嗯，',\n",
       "    'start': 67280,\n",
       "    'end': 67520,\n",
       "    'timestamp': [[67280, 67520]],\n",
       "    'spk': 1},\n",
       "   {'text': '其实还有一些我和朋友的关系也有点紧张，',\n",
       "    'start': 70890,\n",
       "    'end': 71130,\n",
       "    'timestamp': [[67760, 67900],\n",
       "     [67900, 68100],\n",
       "     [68100, 68260],\n",
       "     [68260, 68340],\n",
       "     [68340, 68540],\n",
       "     [68540, 68885],\n",
       "     [69170, 69290],\n",
       "     [69290, 69430],\n",
       "     [69430, 69590],\n",
       "     [69590, 69770],\n",
       "     [69770, 69910],\n",
       "     [69910, 70070],\n",
       "     [70070, 70270],\n",
       "     [70270, 70390],\n",
       "     [70390, 70490],\n",
       "     [70490, 70730],\n",
       "     [70750, 70890],\n",
       "     [70890, 71130]],\n",
       "    'spk': 1},\n",
       "   {'text': '感觉大家都忙着自己的生活，',\n",
       "    'start': 73450,\n",
       "    'end': 73690,\n",
       "    'timestamp': [[71570, 71730],\n",
       "     [71730, 71930],\n",
       "     [71930, 72090],\n",
       "     [72090, 72270],\n",
       "     [72270, 72450],\n",
       "     [72450, 72610],\n",
       "     [72610, 72810],\n",
       "     [72810, 72970],\n",
       "     [72970, 73090],\n",
       "     [73090, 73230],\n",
       "     [73230, 73450],\n",
       "     [73450, 73690]],\n",
       "    'spk': 1},\n",
       "   {'text': '很很少有时间见面。',\n",
       "    'start': 75410,\n",
       "    'end': 75765,\n",
       "    'timestamp': [[73850, 74090],\n",
       "     [74270, 74450],\n",
       "     [74450, 74690],\n",
       "     [74690, 74890],\n",
       "     [74890, 74990],\n",
       "     [74990, 75210],\n",
       "     [75210, 75410],\n",
       "     [75410, 75765]],\n",
       "    'spk': 1},\n",
       "   {'text': '嗯，',\n",
       "    'start': 76500,\n",
       "    'end': 76740,\n",
       "    'timestamp': [[76500, 76740]],\n",
       "    'spk': 0},\n",
       "   {'text': '那听起来有些孤独，',\n",
       "    'start': 77680,\n",
       "    'end': 77920,\n",
       "    'timestamp': [[76780, 76860],\n",
       "     [76860, 76980],\n",
       "     [76980, 77100],\n",
       "     [77100, 77280],\n",
       "     [77280, 77360],\n",
       "     [77360, 77560],\n",
       "     [77560, 77680],\n",
       "     [77680, 77920]],\n",
       "    'spk': 0},\n",
       "   {'text': '你是否有尝试跟他们沟通，',\n",
       "    'start': 79720,\n",
       "    'end': 79960,\n",
       "    'timestamp': [[78160, 78300],\n",
       "     [78300, 78400],\n",
       "     [78400, 78640],\n",
       "     [78720, 78920],\n",
       "     [78920, 79120],\n",
       "     [79120, 79260],\n",
       "     [79260, 79360],\n",
       "     [79360, 79480],\n",
       "     [79480, 79580],\n",
       "     [79580, 79720],\n",
       "     [79720, 79960]],\n",
       "    'spk': 0},\n",
       "   {'text': '表达你的感受呢？',\n",
       "    'start': 80980,\n",
       "    'end': 81220,\n",
       "    'timestamp': [[80080, 80200],\n",
       "     [80200, 80380],\n",
       "     [80380, 80500],\n",
       "     [80500, 80640],\n",
       "     [80640, 80800],\n",
       "     [80800, 80980],\n",
       "     [80980, 81220]],\n",
       "    'spk': 0},\n",
       "   {'text': '我有试过，',\n",
       "    'start': 82120,\n",
       "    'end': 82360,\n",
       "    'timestamp': [[81540, 81700],\n",
       "     [81700, 81900],\n",
       "     [81900, 82120],\n",
       "     [82120, 82360]],\n",
       "    'spk': 1},\n",
       "   {'text': '但是每次都不知道怎么开口，',\n",
       "    'start': 84220,\n",
       "    'end': 84460,\n",
       "    'timestamp': [[82440, 82540],\n",
       "     [82540, 82740],\n",
       "     [82740, 82900],\n",
       "     [82900, 83080],\n",
       "     [83080, 83200],\n",
       "     [83200, 83360],\n",
       "     [83360, 83500],\n",
       "     [83500, 83700],\n",
       "     [83700, 83800],\n",
       "     [83800, 83940],\n",
       "     [83940, 84180],\n",
       "     [84220, 84460]],\n",
       "    'spk': 1},\n",
       "   {'text': '感觉他们怕他们觉得我是在抱怨哦，',\n",
       "    'start': 88580,\n",
       "    'end': 88780,\n",
       "    'timestamp': [[85140, 85300],\n",
       "     [85300, 85540],\n",
       "     [85560, 85760],\n",
       "     [85760, 86000],\n",
       "     [86600, 86840],\n",
       "     [86860, 86960],\n",
       "     [86960, 87120],\n",
       "     [87120, 87260],\n",
       "     [87260, 87380],\n",
       "     [87380, 87580],\n",
       "     [87580, 87740],\n",
       "     [87740, 87940],\n",
       "     [87940, 88160],\n",
       "     [88160, 88400],\n",
       "     [88580, 88780]],\n",
       "    'spk': 1},\n",
       "   {'text': '我理解沟通有时确实很困难，',\n",
       "    'start': 90680,\n",
       "    'end': 90920,\n",
       "    'timestamp': [[88780, 88960],\n",
       "     [88960, 89120],\n",
       "     [89120, 89360],\n",
       "     [89520, 89660],\n",
       "     [89660, 89840],\n",
       "     [89840, 89960],\n",
       "     [89960, 90160],\n",
       "     [90160, 90320],\n",
       "     [90320, 90400],\n",
       "     [90400, 90520],\n",
       "     [90520, 90680],\n",
       "     [90680, 90920]],\n",
       "    'spk': 0},\n",
       "   {'text': '或许我们可以一起练习一下，',\n",
       "    'start': 92620,\n",
       "    'end': 92860,\n",
       "    'timestamp': [[91320, 91520],\n",
       "     [91520, 91640],\n",
       "     [91640, 91720],\n",
       "     [91720, 91820],\n",
       "     [91820, 91900],\n",
       "     [91900, 92000],\n",
       "     [92000, 92080],\n",
       "     [92080, 92200],\n",
       "     [92200, 92360],\n",
       "     [92360, 92540],\n",
       "     [92540, 92620],\n",
       "     [92620, 92860]],\n",
       "    'spk': 0},\n",
       "   {'text': '找找合适的表达方式。',\n",
       "    'start': 94200,\n",
       "    'end': 94440,\n",
       "    'timestamp': [[92860, 93000],\n",
       "     [93000, 93200],\n",
       "     [93200, 93360],\n",
       "     [93360, 93480],\n",
       "     [93480, 93720],\n",
       "     [93800, 93960],\n",
       "     [93960, 94100],\n",
       "     [94100, 94200],\n",
       "     [94200, 94440]],\n",
       "    'spk': 0},\n",
       "   {'text': '好的，',\n",
       "    'start': 95040,\n",
       "    'end': 95280,\n",
       "    'timestamp': [[94840, 95040], [95040, 95280]],\n",
       "    'spk': 1},\n",
       "   {'text': '这样我会觉得很有信心。',\n",
       "    'start': 96780,\n",
       "    'end': 97020,\n",
       "    'timestamp': [[95480, 95580],\n",
       "     [95580, 95780],\n",
       "     [95780, 95880],\n",
       "     [95880, 96060],\n",
       "     [96060, 96180],\n",
       "     [96180, 96320],\n",
       "     [96320, 96420],\n",
       "     [96420, 96620],\n",
       "     [96620, 96780],\n",
       "     [96780, 97020]],\n",
       "    'spk': 1},\n",
       "   {'text': '嗯，',\n",
       "    'start': 97380,\n",
       "    'end': 97620,\n",
       "    'timestamp': [[97380, 97620]],\n",
       "    'spk': 0},\n",
       "   {'text': '太好了，',\n",
       "    'start': 97980,\n",
       "    'end': 98220,\n",
       "    'timestamp': [[97680, 97800], [97800, 97980], [97980, 98220]],\n",
       "    'spk': 0},\n",
       "   {'text': '我们也可以探讨如何在工作和人际关系中找到平衡，',\n",
       "    'start': 101200,\n",
       "    'end': 101440,\n",
       "    'timestamp': [[98240, 98340],\n",
       "     [98340, 98460],\n",
       "     [98460, 98600],\n",
       "     [98600, 98700],\n",
       "     [98700, 98900],\n",
       "     [98900, 99000],\n",
       "     [99000, 99140],\n",
       "     [99140, 99280],\n",
       "     [99280, 99400],\n",
       "     [99400, 99540],\n",
       "     [99540, 99700],\n",
       "     [99700, 99820],\n",
       "     [99820, 100020],\n",
       "     [100020, 100120],\n",
       "     [100120, 100320],\n",
       "     [100320, 100480],\n",
       "     [100480, 100660],\n",
       "     [100660, 100800],\n",
       "     [100800, 100960],\n",
       "     [100960, 101060],\n",
       "     [101060, 101200],\n",
       "     [101200, 101440]],\n",
       "    'spk': 0},\n",
       "   {'text': '帮助你减轻压力。',\n",
       "    'start': 102760,\n",
       "    'end': 103000,\n",
       "    'timestamp': [[101640, 101800],\n",
       "     [101800, 101980],\n",
       "     [101980, 102180],\n",
       "     [102180, 102340],\n",
       "     [102340, 102580],\n",
       "     [102600, 102760],\n",
       "     [102760, 103000]],\n",
       "    'spk': 0},\n",
       "   {'text': '我很期待能学到这些。',\n",
       "    'start': 104620,\n",
       "    'end': 104860,\n",
       "    'timestamp': [[103180, 103300],\n",
       "     [103300, 103540],\n",
       "     [103560, 103720],\n",
       "     [103720, 103900],\n",
       "     [103900, 104040],\n",
       "     [104040, 104200],\n",
       "     [104200, 104400],\n",
       "     [104400, 104620],\n",
       "     [104620, 104860]],\n",
       "    'spk': 1},\n",
       "   {'text': '谢谢您。',\n",
       "    'start': 105520,\n",
       "    'end': 105700,\n",
       "    'timestamp': [[105180, 105340], [105340, 105520], [105520, 105700]],\n",
       "    'spk': 1},\n",
       "   {'text': '李医生啊，',\n",
       "    'start': 106390,\n",
       "    'end': 106510,\n",
       "    'timestamp': [[105700, 105780],\n",
       "     [105780, 105960],\n",
       "     [105960, 106205],\n",
       "     [106390, 106510]],\n",
       "    'spk': 0},\n",
       "   {'text': '不用谢小明，',\n",
       "    'start': 107150,\n",
       "    'end': 107390,\n",
       "    'timestamp': [[106510, 106610],\n",
       "     [106610, 106790],\n",
       "     [106790, 107030],\n",
       "     [107030, 107150],\n",
       "     [107150, 107390]],\n",
       "    'spk': 0},\n",
       "   {'text': '你的勇气值得赞上，',\n",
       "    'start': 108430,\n",
       "    'end': 108670,\n",
       "    'timestamp': [[107410, 107550],\n",
       "     [107550, 107650],\n",
       "     [107650, 107790],\n",
       "     [107790, 108010],\n",
       "     [108010, 108150],\n",
       "     [108150, 108270],\n",
       "     [108270, 108430],\n",
       "     [108430, 108670]],\n",
       "    'spk': 0},\n",
       "   {'text': '我们会一起努力的。',\n",
       "    'start': 109670,\n",
       "    'end': 109935,\n",
       "    'timestamp': [[108750, 108850],\n",
       "     [108850, 108970],\n",
       "     [108970, 109150],\n",
       "     [109150, 109250],\n",
       "     [109250, 109390],\n",
       "     [109390, 109550],\n",
       "     [109550, 109670],\n",
       "     [109670, 109935]],\n",
       "    'spk': 0}]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.010: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.91it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\models\\paraformer\\model.py:251: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n",
      "rtf_avg: 0.299: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.92it/s]\n",
      "rtf_avg: 0.036: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00, 17.95it/s]\n",
      "rtf_avg: 0.117: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.25it/s]\n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 5/5 [00:00<00:00, 44.44it/s]\n",
      "rtf_avg: 0.078: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.74it/s]\n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 9/9 [00:00<00:00, 59.89it/s]\n",
      "rtf_avg: 0.059: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.67it/s]\n",
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 13/13 [00:00<00:00, 75.84it/s]\n",
      "rtf_avg: 0.060: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.65it/s]\n",
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 13/13 [00:00<00:00, 74.71it/s]\n",
      "rtf_avg: 0.058: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.70it/s]\n",
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 13/13 [00:00<00:00, 77.00it/s]\n",
      "rtf_avg: 0.060: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.65it/s]\n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 13/13 [00:00<00:00, 63.23it/s]\n",
      "rtf_avg: 0.055: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.79it/s]\n",
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 13/13 [00:00<00:00, 80.48it/s]\n",
      "rtf_avg: 0.060: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.66it/s]\n",
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 13/13 [00:00<00:00, 79.83it/s]\n",
      "rtf_avg: 0.053: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.59it/s]\n",
      "rtf_avg: 0.010: 100%|\u001b[34m██████████\u001b[0m| 15/15 [00:00<00:00, 63.18it/s]\n",
      "rtf_avg: 0.055: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.54it/s]\n",
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 15/15 [00:00<00:00, 78.10it/s]\n",
      "rtf_avg: 0.049: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.46it/s]\n",
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 18/18 [00:00<00:00, 79.95it/s]\n",
      "rtf_avg: -0.465: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.14it/s]\n",
      "rtf_avg: 0.086, time_speech:  112.800, time_escape: 9.750: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:09<00:00,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗯，小明，谢谢你，今天能来自上次见面，以一来你感觉怎么样？哎，我最近真的很焦虑，胸口像压着一块石头，呼吸都觉得很困难哦，我明白了，能告诉我是什么让你感到如此焦虑吗？主要就是工作上的事情，我有一个重要的项目即将到期了，我现在担心自己没办法拿到预期，听起来真的很有压力。你在想这个项目时，脑海中会出现什么样的想法呢？我总是想象自己会失败，脑海里就像循环播放着各种糟糕的结果，这听起来让人疲惫。你有没有找到一些方法来应对这些困扰你的想法？我试过深呼吸，但是有时候我觉得这只会让我更加觉上，而不是帮助。这很正常。有些方法对每个人效果不一样，你愿意一起探讨一些其他的技巧吗？也许我们可以找到对你更有效的方法。好呀，我愿意试试。呃，那么除了工作上的压力，你在生活中还有其他让你感到困扰的事情吗？嗯，其实还有一些我和朋友的关系也有点紧张，感觉大家都忙着自己的生活，很很少有时间见面。嗯，那听起来有些孤独，你是否有尝试跟他们沟通，表达你的感受呢？我有试过，但是每次都不知道怎么开口感觉他们怕他们觉得我是在抱怨哦，我理解沟通有时确实很困难。或许我们可以一起练习一下，找找合适的表达方式。好的，这样我会觉得很有信心。嗯，太好了，我们也可以探讨如何在工作和人际关系中找到平衡，帮助你减轻压力。我很期待能学到这些。谢谢您。李医生啊，不用谢小明，你的勇气值得赞上，我们会一起努力的。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Speaker 0: 嗯，',\n",
       " 'Speaker 0: 小明，',\n",
       " 'Speaker 0: 谢谢你，',\n",
       " 'Speaker 0: 今天能来自上次见面，',\n",
       " 'Speaker 0: 以一来你感觉怎么样？',\n",
       " 'Speaker 1: 哎，',\n",
       " 'Speaker 1: 我最近真的很焦虑，',\n",
       " 'Speaker 1: 胸口像压着一块石头，',\n",
       " 'Speaker 0: 呼吸都觉得很困难哦，',\n",
       " 'Speaker 0: 我明白了，',\n",
       " 'Speaker 0: 能告诉我是什么让你感到如此焦虑吗？',\n",
       " 'Speaker 1: 主要就是工作上的事情，',\n",
       " 'Speaker 1: 我有一个重要的项目即将到期了，',\n",
       " 'Speaker 1: 我现在担心自己没办法拿到预期，',\n",
       " 'Speaker 0: 听起来真的很有压力。',\n",
       " 'Speaker 0: 你在想这个项目时，',\n",
       " 'Speaker 1: 脑海中会出现什么样的想法呢？',\n",
       " 'Speaker 1: 我总是想象自己会失败，',\n",
       " 'Speaker 1: 脑海里就像循环播放着各种糟糕的结果，',\n",
       " 'Speaker 0: 这听起来让人疲惫。',\n",
       " 'Speaker 0: 你有没有找到一些方法来应对这些困扰你的想法？',\n",
       " 'Speaker 1: 我试过深呼吸，',\n",
       " 'Speaker 1: 但是有时候我觉得这只会让我更加觉上，',\n",
       " 'Speaker 0: 而不是帮助。',\n",
       " 'Speaker 0: 这很正常。',\n",
       " 'Speaker 0: 有些方法对每个人效果不一样，',\n",
       " 'Speaker 0: 你愿意一起探讨一些其他的技巧吗？',\n",
       " 'Speaker 1: 也许我们可以找到对你更有效的方法。',\n",
       " 'Speaker 1: 好呀，',\n",
       " 'Speaker 1: 我愿意试试。',\n",
       " 'Speaker 0: 呃，',\n",
       " 'Speaker 0: 那么除了工作上的压力，',\n",
       " 'Speaker 1: 你在生活中还有其他让你感到困扰的事情吗？',\n",
       " 'Speaker 1: 嗯，',\n",
       " 'Speaker 1: 其实还有一些我和朋友的关系也有点紧张，',\n",
       " 'Speaker 1: 感觉大家都忙着自己的生活，',\n",
       " 'Speaker 1: 很很少有时间见面。',\n",
       " 'Speaker 0: 嗯，',\n",
       " 'Speaker 0: 那听起来有些孤独，',\n",
       " 'Speaker 0: 你是否有尝试跟他们沟通，',\n",
       " 'Speaker 0: 表达你的感受呢？',\n",
       " 'Speaker 1: 我有试过，',\n",
       " 'Speaker 1: 但是每次都不知道怎么开口感觉他们怕他们觉得我是在抱怨哦，',\n",
       " 'Speaker 0: 我理解沟通有时确实很困难。',\n",
       " 'Speaker 0: 或许我们可以一起练习一下，',\n",
       " 'Speaker 0: 找找合适的表达方式。',\n",
       " 'Speaker 1: 好的，',\n",
       " 'Speaker 1: 这样我会觉得很有信心。',\n",
       " 'Speaker 0: 嗯，',\n",
       " 'Speaker 0: 太好了，',\n",
       " 'Speaker 0: 我们也可以探讨如何在工作和人际关系中找到平衡，',\n",
       " 'Speaker 1: 帮助你减轻压力。',\n",
       " 'Speaker 1: 我很期待能学到这些。',\n",
       " 'Speaker 1: 谢谢您。',\n",
       " 'Speaker 0: 李医生啊，',\n",
       " 'Speaker 0: 不用谢小明，',\n",
       " 'Speaker 0: 你的勇气值得赞上，',\n",
       " 'Speaker 0: 我们会一起努力的。']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.generate(\n",
    "    input=speech,\n",
    "    cache={},\n",
    "    language=\"zn\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)\n",
    "\n",
    "com = []\n",
    "for i in res:\n",
    "   for j in i['sentence_info']:\n",
    "    #   print(\"Text: \", j['text'])\n",
    "    #   print( \"Speaker: \", j['spk'])\n",
    "      com.append(f'Speaker {j['spk']}: {j['text']}')\n",
    "\n",
    "com\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(com[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SenseVoiceSmall Model with vad model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New version available: 1.1.12. Your current version is 1.1.2.\n",
      "Please use the command \"pip install -U funasr\" to upgrade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 15:06:10,233 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miic/SenseVoiceSmall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m     \u001b[49m\u001b[43mvad_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfsmn-vad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m     \u001b[49m\u001b[43mvad_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_single_segment_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30000\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#punc_model = \"ct-punc\"\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# en\u001b[39;00m\n\u001b[0;32m     10\u001b[0m res \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39maudio_16KHz,\n\u001b[0;32m     12\u001b[0m     cache\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     merge_length_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\auto\\auto_model.py:124\u001b[0m, in \u001b[0;36mAutoModel.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m log_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(logging, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_level\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mupper())\n\u001b[0;32m    122\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(level\u001b[38;5;241m=\u001b[39mlog_level)\n\u001b[1;32m--> 124\u001b[0m model, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# if vad_model is not None, build vad model else None\u001b[39;00m\n\u001b[0;32m    127\u001b[0m vad_model \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvad_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\auto\\auto_model.py:222\u001b[0m, in \u001b[0;36mAutoModel.build_model\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m deep_update(model_conf, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_conf\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m    221\u001b[0m deep_update(model_conf, kwargs)\n\u001b[1;32m--> 222\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# init_param\u001b[39;00m\n\u001b[0;32m    225\u001b[0m init_param \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_param\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\models\\sense_voice\\model.py:618\u001b[0m, in \u001b[0;36mSenseVoiceSmall.__init__\u001b[1;34m(self, specaug, specaug_conf, normalize, normalize_conf, encoder, encoder_conf, ctc_conf, input_size, vocab_size, ignore_id, blank_id, sos, eos, length_normalized_loss, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m     normalize \u001b[38;5;241m=\u001b[39m normalize_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnormalize_conf)\n\u001b[0;32m    617\u001b[0m encoder_class \u001b[38;5;241m=\u001b[39m tables\u001b[38;5;241m.\u001b[39mencoder_classes\u001b[38;5;241m.\u001b[39mget(encoder)\n\u001b[1;32m--> 618\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_conf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m encoder_output_size \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39moutput_size()\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctc_conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\models\\sense_voice\\model.py:525\u001b[0m, in \u001b[0;36mSenseVoiceEncoderSmall.__init__\u001b[1;34m(self, input_size, output_size, attention_heads, linear_units, num_blocks, tp_blocks, dropout_rate, positional_dropout_rate, attention_dropout_rate, stochastic_depth_rate, input_layer, pos_enc_class, normalize_before, concat_after, positionwise_layer_type, positionwise_conv_kernel_size, padding_idx, kernel_size, sanm_shfit, selfattention_layer_type, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m encoder_selfattn_layer_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    499\u001b[0m     attention_heads,\n\u001b[0;32m    500\u001b[0m     output_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m     sanm_shfit,\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoders0 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m    508\u001b[0m     [\n\u001b[0;32m    509\u001b[0m         EncoderLayerSANM(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m     ]\n\u001b[0;32m    518\u001b[0m )\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoders \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m    520\u001b[0m     [\n\u001b[0;32m    521\u001b[0m         EncoderLayerSANM(\n\u001b[0;32m    522\u001b[0m             output_size,\n\u001b[0;32m    523\u001b[0m             output_size,\n\u001b[0;32m    524\u001b[0m             encoder_selfattn_layer(\u001b[38;5;241m*\u001b[39mencoder_selfattn_layer_args),\n\u001b[1;32m--> 525\u001b[0m             \u001b[43mpositionwise_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpositionwise_layer_args\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    526\u001b[0m             dropout_rate,\n\u001b[0;32m    527\u001b[0m         )\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_blocks \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    529\u001b[0m     ]\n\u001b[0;32m    530\u001b[0m )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtp_encoders \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m    533\u001b[0m     [\n\u001b[0;32m    534\u001b[0m         EncoderLayerSANM(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m     ]\n\u001b[0;32m    543\u001b[0m )\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_norm \u001b[38;5;241m=\u001b[39m LayerNorm(output_size)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\funasr\\models\\sense_voice\\model.py:71\u001b[0m, in \u001b[0;36mPositionwiseFeedForward.__init__\u001b[1;34m(self, idim, hidden_units, dropout_rate, activation)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m(PositionwiseFeedForward, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(idim, hidden_units)\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDropout(dropout_rate)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activation\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:104\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:110\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\init.py:460\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[1;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[0;32m    458\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoModel(\n",
    "    model='iic/SenseVoiceSmall',\n",
    "     vad_model=\"fsmn-vad\",\n",
    "     vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "    device=\"cuda:0\",\n",
    "    #punc_model = \"ct-punc\"\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_16KHz,\n",
    "    cache={},\n",
    "    language=\"zn\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# Load the processor and model\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No librosa attribute record",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m(duration)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_audio\u001b[39m(duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Record audio for a specified duration\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord\u001b[49m(duration\u001b[38;5;241m=\u001b[39mduration, sr\u001b[38;5;241m=\u001b[39msample_rate)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lazy_loader\\__init__.py:94\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attr\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: No librosa attribute record"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Set the sampling rate\n",
    "sample_rate = 16000\n",
    "\n",
    "def record_audio(duration=5):\n",
    "    # Record audio for a specified duration\n",
    "    audio = librosa.record(duration=duration, sr=sample_rate)\n",
    "    return audio\n",
    "\n",
    "# Example usage\n",
    "audio_data = record_audio(duration=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No librosa attribute record",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Record for 5 seconds\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Convert audio data to the format required by the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     audio_input \u001b[38;5;241m=\u001b[39m processor(audio_data, sampling_rate\u001b[38;5;241m=\u001b[39msample_rate, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m(duration)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_audio\u001b[39m(duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Record audio for a specified duration\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord\u001b[49m(duration\u001b[38;5;241m=\u001b[39mduration, sr\u001b[38;5;241m=\u001b[39msample_rate)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lazy_loader\\__init__.py:94\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attr\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: No librosa attribute record"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    audio_data = record_audio(duration=5)  # Record for 5 seconds\n",
    "\n",
    "    # Convert audio data to the format required by the model\n",
    "    audio_input = processor(audio_data, sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "\n",
    "    # Use the model to transcribe the audio\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**audio_input)\n",
    "\n",
    "    # Decode the generated ids to get the transcription\n",
    "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensevoice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
